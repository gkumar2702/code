stages:
  - pylint
  - deploy_test
before_script:
  - export TZ='Asia/Kolkata'
pylint_check:
  image: ubuntu:16.04
  stage: pylint
  tags: ["stages"]
  only:
    changes:
      - Testing/Production DAG/*
      - Testing/Production Code/*
      - .gitlab-ci.yml
      - requirements.txt
  before_script:
    - apt-get update
    - apt-get install default-jdk -y
  script:
    - apt update
    - apt install python3 -qy
    - apt install python3-pip -qy
    - pip3 install --upgrade pip
    - pip3 install -r requirements.txt
    - pwd
    - cd "Testing/Production Code"
    - pylint --exit-zero output_collation_pylint.py
    - pylint --exit-zero output_collation_pylint.py > lint_sc_one.txt
    - score_sc=$(tail -2 lint_sc_one.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint --exit-zero storm_level_comparison_pylint.py > lint_sc_two.txt
    - score_sc=$(tail -2 lint_sc_two.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint --exit-zero weathersource_script_pylint.py	 > lint_sc_three.txt
    - score_sc=$(tail -2 lint_sc_three.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint -j 0 --exit-zero --ignored-modules=pyspark.sql.functions --extension-pkg-whitelist=pyspark --generated-members=pyspark.* curated_dataset_creation_pylint.py > lint_sc_four.txt
    - score_sc=$(tail -2 lint_sc_four.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint -j 0 --exit-zero --ignored-modules=pyspark.sql.functions --extension-pkg-whitelist=pyspark --generated-members=pyspark.* load_predict_pylint.py > lint_sc_six.txt
    - score_sc=$(tail -2 lint_sc_six.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint -j 0 --exit-zero --ignored-modules=pyspark.sql.functions --extension-pkg-whitelist=pyspark --generated-members=pyspark.* weather_source_data_collation_pylint.py > lint_sc_seven.txt
    - score_sc=$(tail -2 lint_sc_seven.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi
    - pylint -j 0 --exit-zero --ignored-modules=pyspark.sql.functions --extension-pkg-whitelist=pyspark --generated-members=pyspark.* live_oms_preprocessing_pylint.py > lint_sc_five.txt
    - score_sc=$(tail -2 lint_sc_five.txt | awk '{print $7}' | cut -d/ -f1)
    - echo ${score_sc%.*}
    - if [ ${score_sc%.*} -gt 5 ]; then echo "PASSED"; else echo "FAILED" && exit 1; fi

deploying_dag_file_into_gcs-prod:
  stage: deploy_test
#  when: manual
  image: google/cloud-sdk
  tags: ["stages"]
  only: 
    - dev
  only:
    changes:
      - Testing/Production DAG/*
      - Testing/Production Code/*
  script:
    - apt-get install python3-openssl -qy
    - echo 'nameserver 1.1.1.1'  > /etc/resolv.conf
    - echo 'nameserver 1.0.0.1' >> /etc/resolv.conf
    - mkdir -p ./creds
    - echo $password_dev | base64 -d > ./creds/password_dev.json
    - export GOOGLE_CREDENTIALS=$(cat ./creds/password_dev.json)
    - gcloud auth activate-service-account $service_account_dev --key-file=./creds/password_dev.json
    - gsutil rsync "Testing/Production DAG/"  gs://us-east4-composer-0002-8d07c42c-bucket/dags/
    - gsutil rsync "Testing/Production Code/"  gs://us-east4-composer-0002-8d07c42c-bucket/data/Outage_restoration/IPL/Python_scripts/


